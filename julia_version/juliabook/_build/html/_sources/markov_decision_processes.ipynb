{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e231c5e7",
   "metadata": {},
   "source": [
    "(Chapter 5: Markov Decision Processes)=\n",
    "```{raw} html\n",
    "<div id=\"qe-notebook-header\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>\n",
    "```\n",
    "# Chapter 5: Markov Decision Processes\n",
    "\n",
    "\n",
    "```{contents} Contents\n",
    ":depth: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3137be08",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "Pkg.activate(\"../\");\n",
    "\n",
    "using PyCall;\n",
    "pygui(:tk);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90683ab5",
   "metadata": {},
   "source": [
    "#### inventory_dp.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4887965",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "include(\"s_approx.jl\")\n",
    "using Distributions\n",
    "m(x) = max(x, 0)  # Convenience function\n",
    "\n",
    "function create_inventory_model(; β=0.98,     # discount factor\n",
    "                                  K=40,       # maximum inventory\n",
    "                                  c=0.2, κ=2, # cost paramters\n",
    "                                  p=0.6)      # demand parameter\n",
    "    ϕ(d) = (1 - p)^d * p        # demand pdf\n",
    "    x_vals = collect(0:K)       # set of inventory levels\n",
    "    return (; β, K, c, κ, p, ϕ, x_vals)\n",
    "end\n",
    "\n",
    "\"The function B(x, a, v) = r(x, a) + β Σ_x′ v(x′) P(x, a, x′).\"\n",
    "function B(x, a, v, model; d_max=100)\n",
    "    (; β, K, c, κ, p, ϕ, x_vals) = model\n",
    "    revenue = sum(min(x, d) * ϕ(d) for d in 0:d_max) \n",
    "    current_profit = revenue - c * a - κ * (a > 0)\n",
    "    next_value = sum(v[m(x - d) + a + 1] * ϕ(d) for d in 0:d_max)\n",
    "    return current_profit + β * next_value\n",
    "end\n",
    "\n",
    "\"The Bellman operator.\"\n",
    "function T(v, model)\n",
    "    (; β, K, c, κ, p, ϕ, x_vals) = model\n",
    "    new_v = similar(v)\n",
    "    for (x_idx, x) in enumerate(x_vals)\n",
    "        Γx = 0:(K - x) \n",
    "        new_v[x_idx], _ = findmax(B(x, a, v, model) for a in Γx)\n",
    "    end\n",
    "    return new_v\n",
    "end\n",
    "\n",
    "\"Get a v-greedy policy.  Returns a zero-based array.\"\n",
    "function get_greedy(v, model)\n",
    "    (; β, K, c, κ, p, ϕ, x_vals) = model\n",
    "    σ_star = zero(x_vals)\n",
    "    for (x_idx, x) in enumerate(x_vals)\n",
    "        Γx = 0:(K - x) \n",
    "        _, a_idx = findmax(B(x, a, v, model) for a in Γx)\n",
    "        σ_star[x_idx] = Γx[a_idx]\n",
    "    end\n",
    "    return σ_star\n",
    "end\n",
    "\n",
    "\"Use successive_approx to get v_star and then compute greedy.\"\n",
    "function solve_inventory_model(v_init, model)\n",
    "    (; β, K, c, κ, p, ϕ, x_vals) = model\n",
    "    v_star = successive_approx(v -> T(v, model), v_init)\n",
    "    σ_star = get_greedy(v_star, model)\n",
    "    return v_star, σ_star\n",
    "end\n",
    "\n",
    "# == Plots == # \n",
    "\n",
    "using PyPlot\n",
    "using PyPlot\n",
    "using LaTeXStrings\n",
    "PyPlot.matplotlib[:rc](\"text\", usetex=true) # allow tex rendering\n",
    "\n",
    "# Create an instance of the model and solve it\n",
    "model = create_inventory_model()\n",
    "(; β, K, c, κ, p, ϕ, x_vals) = model\n",
    "v_init = zeros(length(x_vals))\n",
    "v_star, σ_star = solve_inventory_model(v_init, model)\n",
    "\n",
    "\"Simulate given the optimal policy.\"\n",
    "function sim_inventories(ts_length=400, X_init=0)\n",
    "    G = Geometric(p)\n",
    "    X = zeros(Int32, ts_length)\n",
    "    X[1] = X_init\n",
    "    for t in 1:(ts_length-1)\n",
    "        D = rand(G)\n",
    "        X[t+1] = m(X[t] - D) + σ_star[X[t] + 1]\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "\n",
    "function plot_vstar_and_opt_policy(; fontsize=16, \n",
    "                   figname=\"../figures/inventory_dp_vs.pdf\",\n",
    "                   savefig=false)\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(8, 6.5))\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.plot(0:K, v_star, label=L\"v^*\")\n",
    "    ax.set_ylabel(\"value\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize, frameon=false)\n",
    "\n",
    "    ax = axes[2]\n",
    "    ax.plot(0:K, σ_star, label=L\"\\sigma^*\")\n",
    "    ax.set_xlabel(\"inventory\", fontsize=fontsize)\n",
    "    ax.set_ylabel(\"optimal choice\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize, frameon=false)\n",
    "    if savefig == true\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n",
    "\n",
    "function plot_ts(; fontsize=16, \n",
    "                   figname=\"../figures/inventory_dp_ts.pdf\",\n",
    "                   savefig=false)\n",
    "    X = sim_inventories()\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.5))\n",
    "    ax.plot(X, label=L\"X_t\", alpha=0.7)\n",
    "    ax.set_xlabel(L\"t\", fontsize=fontsize)\n",
    "    ax.set_ylabel(\"inventory\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize, frameon=false)\n",
    "    ax.set_ylim(0, maximum(X)+4)\n",
    "    if savefig == true\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vstar_and_opt_policy(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b36f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ts(savefig=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5eee8",
   "metadata": {},
   "source": [
    "#### finite_opt_saving_0.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d03c0",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "using QuantEcon, LinearAlgebra, IterTools\n",
    "\n",
    "function create_savings_model(; R=1.01, β=0.98, γ=2.5,  \n",
    "                                w_min=0.01, w_max=20.0, w_size=200,\n",
    "                                ρ=0.9, ν=0.1, y_size=5)\n",
    "    w_grid = LinRange(w_min, w_max, w_size)  \n",
    "    mc = tauchen(y_size, ρ, ν)\n",
    "    y_grid, Q = exp.(mc.state_values), mc.p\n",
    "    return (; β, R, γ, w_grid, y_grid, Q)\n",
    "end\n",
    "\n",
    "\"B(w, y, w′, v) = u(R*w + y - w′) + β Σ_y′ v(w′, y′) Q(y, y′).\"\n",
    "function B(i, j, k, v, model)\n",
    "    (; β, R, γ, w_grid, y_grid, Q) = model\n",
    "    w, y, w′ = w_grid[i], y_grid[j], w_grid[k]\n",
    "    u(c) = c^(1-γ) / (1-γ)\n",
    "    c = w + y - (w′ / R)\n",
    "    @views value = c > 0 ? u(c) + β * dot(v[k, :], Q[j, :]) : -Inf\n",
    "    return value\n",
    "end\n",
    "\n",
    "\"The Bellman operator.\"\n",
    "function T(v, model)\n",
    "    w_idx, y_idx = (eachindex(g) for g in (model.w_grid, model.y_grid))\n",
    "    v_new = similar(v)\n",
    "    for (i, j) in product(w_idx, y_idx)\n",
    "        v_new[i, j] = maximum(B(i, j, k, v, model) for k in w_idx)\n",
    "    end\n",
    "    return v_new\n",
    "end\n",
    "\n",
    "\"The policy operator.\"\n",
    "function T_σ(v, σ, model)\n",
    "    w_idx, y_idx = (eachindex(g) for g in (model.w_grid, model.y_grid))\n",
    "    v_new = similar(v)\n",
    "    for (i, j) in product(w_idx, y_idx)\n",
    "        v_new[i, j] = B(i, j, σ[i, j], v, model) \n",
    "    end\n",
    "    return v_new\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa6351",
   "metadata": {},
   "source": [
    "#### finite_opt_saving_1.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2fb60",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "include(\"finite_opt_saving_0.jl\")\n",
    "\n",
    "\"Compute a v-greedy policy.\"\n",
    "function get_greedy(v, model)\n",
    "    w_idx, y_idx = (eachindex(g) for g in (model.w_grid, model.y_grid))\n",
    "    σ = Matrix{Int32}(undef, length(w_idx), length(y_idx))\n",
    "    for (i, j) in product(w_idx, y_idx)\n",
    "        _, σ[i, j] = findmax(B(i, j, k, v, model) for k in w_idx)\n",
    "    end\n",
    "    return σ\n",
    "end\n",
    "\n",
    "\"Get the value v_σ of policy σ.\"\n",
    "function get_value(σ, model)\n",
    "    # Unpack and set up\n",
    "    (; β, R, γ, w_grid, y_grid, Q) = model\n",
    "    w_idx, y_idx = (eachindex(g) for g in (w_grid, y_grid))\n",
    "    wn, yn = length(w_idx), length(y_idx)\n",
    "    n = wn * yn\n",
    "    u(c) = c^(1-γ) / (1-γ)\n",
    "    # Build P_σ and r_σ as multi-index arrays\n",
    "    P_σ = zeros(wn, yn, wn, yn)\n",
    "    r_σ = zeros(wn, yn)\n",
    "    for (i, j) in product(w_idx, y_idx)\n",
    "            w, y, w′ = w_grid[i], y_grid[j], w_grid[σ[i, j]]\n",
    "            r_σ[i, j] = u(w + y - w′/R)\n",
    "        for (i′, j′) in product(w_idx, y_idx)\n",
    "            if i′ == σ[i, j]\n",
    "                P_σ[i, j, i′, j′] = Q[j, j′]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    # Reshape for matrix algebra\n",
    "    P_σ = reshape(P_σ, n, n)\n",
    "    r_σ = reshape(r_σ, n)\n",
    "    # Apply matrix operations --- solve for the value of σ \n",
    "    v_σ = (I - β * P_σ) \\ r_σ\n",
    "    # Return as multi-index array\n",
    "    return reshape(v_σ, wn, yn)\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a31b59",
   "metadata": {},
   "source": [
    "#### finite_opt_saving_2.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3c315",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "include(\"s_approx.jl\")\n",
    "include(\"finite_opt_saving_1.jl\")\n",
    "\n",
    "\"Value function iteration routine.\"\n",
    "function value_iteration(model, tol=1e-5)\n",
    "    vz = zeros(length(model.w_grid), length(model.y_grid))\n",
    "    v_star = successive_approx(v -> T(v, model), vz, tolerance=tol)\n",
    "    return get_greedy(v_star, model)\n",
    "end\n",
    "\n",
    "\"Howard policy iteration routine.\"\n",
    "function policy_iteration(model)\n",
    "    wn, yn = length(model.w_grid), length(model.y_grid)\n",
    "    σ = ones(Int32, wn, yn)\n",
    "    i, error = 0, 1.0\n",
    "    while error > 0\n",
    "        v_σ = get_value(σ, model)\n",
    "        σ_new = get_greedy(v_σ, model)\n",
    "        error = maximum(abs.(σ_new - σ))\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        println(\"Concluded loop $i with error $error.\")\n",
    "    end\n",
    "    return σ\n",
    "end\n",
    "\n",
    "\"Optimistic policy iteration routine.\"\n",
    "function optimistic_policy_iteration(model; tolerance=1e-5, m=100)\n",
    "    v = zeros(length(model.w_grid), length(model.y_grid))\n",
    "    error = tolerance + 1\n",
    "    while error > tolerance\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        for i in 1:m\n",
    "            v = T_σ(v, σ, model)\n",
    "        end\n",
    "        error = maximum(abs.(v - last_v))\n",
    "    end\n",
    "    return get_greedy(v, model)\n",
    "end\n",
    "\n",
    "# == Simulations and inequality measures == #\n",
    "\n",
    "function simulate_wealth(m)\n",
    "\n",
    "    model = create_savings_model()\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "    (; β, R, γ, w_grid, y_grid, Q) = model\n",
    "\n",
    "    # Simulate labor income (indices rather than grid values)\n",
    "    mc = MarkovChain(Q)\n",
    "    y_idx_series = simulate(mc, m)\n",
    "\n",
    "    # Compute corresponding wealth time series\n",
    "    w_idx_series = similar(y_idx_series)\n",
    "    w_idx_series[1] = 1  # initial condition\n",
    "    for t in 1:(m-1)\n",
    "        i, j = w_idx_series[t], y_idx_series[t]\n",
    "        w_idx_series[t+1] = σ_star[i, j]\n",
    "    end\n",
    "    w_series = w_grid[w_idx_series]\n",
    "\n",
    "    return w_series\n",
    "end\n",
    "\n",
    "function lorenz(v)  # assumed sorted vector\n",
    "    S = cumsum(v)  # cumulative sums: [v[1], v[1] + v[2], ... ]\n",
    "    F = (1:length(v)) / length(v)\n",
    "    L = S ./ S[end]\n",
    "    return (; F, L) # returns named tuple\n",
    "end\n",
    "\n",
    "gini(v) = (2 * sum(i * y for (i,y) in enumerate(v))/sum(v)\n",
    "           - (length(v) + 1))/length(v)\n",
    "\n",
    "\n",
    "\n",
    "# == Plots == #\n",
    "\n",
    "using PyPlot\n",
    "using LaTeXStrings\n",
    "PyPlot.matplotlib[:rc](\"text\", usetex=true) # allow tex rendering\n",
    "fontsize=16\n",
    "\n",
    "function plot_timing(; m_vals=collect(range(1, 600, step=10)),\n",
    "                       savefig=false)\n",
    "    model = create_savings_model(y_size=5)\n",
    "    println(\"Running Howard policy iteration.\")\n",
    "    pi_time = @elapsed σ_pi = policy_iteration(model)\n",
    "    println(\"PI completed in $pi_time seconds.\")\n",
    "    println(\"Running value function iteration.\")\n",
    "    vfi_time = @elapsed σ_vfi = value_iteration(model)\n",
    "    println(\"VFI completed in $vfi_time seconds.\")\n",
    "    @assert σ_vfi == σ_pi \"Warning: policies deviated.\"\n",
    "    opi_times = []\n",
    "    for m in m_vals\n",
    "        println(\"Running optimistic policy iteration with m=$m.\")\n",
    "        opi_time = @elapsed σ_opi = optimistic_policy_iteration(model, m=m)\n",
    "        @assert σ_opi == σ_pi \"Warning: policies deviated.\"\n",
    "        println(\"OPI with m=$m completed in $opi_time seconds.\")\n",
    "        push!(opi_times, opi_time)\n",
    "    end\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(m_vals, fill(vfi_time, length(m_vals)), \n",
    "            lw=2, label=\"value function iteration\")\n",
    "    ax.plot(m_vals, fill(pi_time, length(m_vals)), \n",
    "            lw=2, label=\"Howard policy iteration\")\n",
    "    ax.plot(m_vals, opi_times, lw=2, label=\"optimistic policy iteration\")\n",
    "    ax.legend(fontsize=fontsize, frameon=false)\n",
    "    ax.set_xlabel(L\"m\", fontsize=fontsize)\n",
    "    ax.set_ylabel(\"time\", fontsize=fontsize)\n",
    "    if savefig\n",
    "        fig.savefig(\"../figures/finite_opt_saving_2_1.pdf\")\n",
    "    end\n",
    "    return (pi_time, vfi_time, opi_times)\n",
    "end\n",
    "\n",
    "function plot_policy(; method=\"pi\")\n",
    "    model = create_savings_model()\n",
    "    (; β, R, γ, w_grid, y_grid, Q) = model\n",
    "    if method == \"vfi\"\n",
    "        σ_star =  value_iteration(model) \n",
    "    elseif method == \"pi\"\n",
    "        σ_star = policy_iteration(model) \n",
    "    else\n",
    "        σ_star = optimistic_policy_iteration(model)\n",
    "    end\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_grid, w_grid, \"k--\", label=L\"45\")\n",
    "    ax.plot(w_grid, w_grid[σ_star[:, 1]], label=L\"\\sigma^*(\\cdot, y_1)\")\n",
    "    ax.plot(w_grid, w_grid[σ_star[:, end]], label=L\"\\sigma^*(\\cdot, y_N)\")\n",
    "    ax.legend(fontsize=fontsize)\n",
    "end\n",
    "\n",
    "\n",
    "function plot_time_series(; m=2_000,\n",
    "                           savefig=false, \n",
    "                           figname=\"../figures/finite_opt_saving_ts.pdf\")\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_series, label=L\"w_t\")\n",
    "    ax.set_xlabel(\"time\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize)\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n",
    "\n",
    "function plot_histogram(; m=1_000_000,\n",
    "                           savefig=false, \n",
    "                           figname=\"../figures/finite_opt_saving_hist.pdf\")\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    g = round(gini(sort(w_series)), digits=2)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.hist(w_series, bins=40, density=true)\n",
    "    ax.set_xlabel(\"wealth\", fontsize=fontsize)\n",
    "    ax.text(15, 0.4, \"Gini = $g\", fontsize=fontsize)\n",
    "\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n",
    "\n",
    "function plot_lorenz(; m=1_000_000,\n",
    "                           savefig=false, \n",
    "                           figname=\"../figures/finite_opt_saving_lorenz.pdf\")\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    (; F, L) = lorenz(sort(w_series))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(F, F, label=\"Lorenz curve, equality\")\n",
    "    ax.plot(F, L, label=\"Lorenz curve, wealth distribution\")\n",
    "    ax.legend()\n",
    "\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26582f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timing(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc95856",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a91a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(savefig=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e155d6",
   "metadata": {},
   "source": [
    "#### finite_lq.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bfdd7",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "using QuantEcon, LinearAlgebra, IterTools\n",
    "include(\"s_approx.jl\")\n",
    "\n",
    "function create_investment_model(; \n",
    "        r=0.04,                              # Interest rate\n",
    "        a_0=10.0, a_1=1.0,                   # Demand parameters\n",
    "        γ=25.0, c=1.0,                       # Adjustment and unit cost \n",
    "        y_min=0.0, y_max=20.0, y_size=100,   # Grid for output\n",
    "        ρ=0.9, ν=1.0,                        # AR(1) parameters\n",
    "        z_size=25)                           # Grid size for shock\n",
    "    β = 1/(1+r) \n",
    "    y_grid = LinRange(y_min, y_max, y_size)  \n",
    "    mc = tauchen(y_size, ρ, ν)\n",
    "    z_grid, Q = mc.state_values, mc.p\n",
    "    return (; β, a_0, a_1, γ, c, y_grid, z_grid, Q)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "The aggregator B is given by \n",
    "\n",
    "    B(y, z, y′) = r(y, z, y′) + β Σ_z′ v(y′, z′) Q(z, z′).\"\n",
    "\n",
    "where \n",
    "\n",
    "    r(y, z, y′) := (a_0 - a_1 * y + z - c) y - γ * (y′ - y)^2\n",
    "\n",
    "\"\"\"\n",
    "function B(i, j, k, v, model)\n",
    "    (; β, a_0, a_1, γ, c, y_grid, z_grid, Q) = model\n",
    "    y, z, y′ = y_grid[i], z_grid[j], y_grid[k]\n",
    "    r = (a_0 - a_1 * y + z - c) * y - γ * (y′ - y)^2\n",
    "    return @views r + β * dot(v[k, :], Q[j, :]) \n",
    "end\n",
    "\n",
    "\"The policy operator.\"\n",
    "function T_σ(v, σ, model)\n",
    "    y_idx, z_idx = (eachindex(g) for g in (model.y_grid, model.z_grid))\n",
    "    v_new = similar(v)\n",
    "    for (i, j) in product(y_idx, z_idx)\n",
    "        v_new[i, j] = B(i, j, σ[i, j], v, model) \n",
    "    end\n",
    "    return v_new\n",
    "end\n",
    "\n",
    "\"The Bellman operator.\"\n",
    "function T(v, model)\n",
    "    y_idx, z_idx = (eachindex(g) for g in (model.y_grid, model.z_grid))\n",
    "    v_new = similar(v)\n",
    "    for (i, j) in product(y_idx, z_idx)\n",
    "        v_new[i, j] = maximum(B(i, j, k, v, model) for k in y_idx)\n",
    "    end\n",
    "    return v_new\n",
    "end\n",
    "\n",
    "\"Compute a v-greedy policy.\"\n",
    "function get_greedy(v, model)\n",
    "    y_idx, z_idx = (eachindex(g) for g in (model.y_grid, model.z_grid))\n",
    "    σ = Matrix{Int32}(undef, length(y_idx), length(z_idx))\n",
    "    for (i, j) in product(y_idx, z_idx)\n",
    "        _, σ[i, j] = findmax(B(i, j, k, v, model) for k in y_idx)\n",
    "    end\n",
    "    return σ\n",
    "end\n",
    "\n",
    "\"Value function iteration routine.\"\n",
    "function value_iteration(model; tol=1e-5)\n",
    "    vz = zeros(length(model.y_grid), length(model.z_grid))\n",
    "    v_star = successive_approx(v -> T(v, model), vz, tolerance=tol)\n",
    "    return get_greedy(v_star, model)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\"Get the value v_σ of policy σ.\"\n",
    "function get_value(σ, model)\n",
    "    # Unpack and set up\n",
    "    (; β, a_0, a_1, γ, c, y_grid, z_grid, Q) = model\n",
    "    yn, zn = length(y_grid), length(z_grid)\n",
    "    n = yn * zn\n",
    "    # Function to extract (i, j) from m = i + (j-1)*yn\"\n",
    "    single_to_multi(m) = (m-1)%yn + 1, div(m-1, yn) + 1\n",
    "    # Allocate and create single index versions of P_σ and r_σ\n",
    "    P_σ = zeros(n, n)\n",
    "    r_σ = zeros(n)\n",
    "    for m in 1:n\n",
    "        i, j = single_to_multi(m)\n",
    "        y, z, y′ = y_grid[i], z_grid[j], y_grid[σ[i, j]]\n",
    "        r_σ[m] = (a_0 - a_1 * y + z - c) * y - γ * (y′ - y)^2\n",
    "        for m′ in 1:n\n",
    "            i′, j′ = single_to_multi(m′)\n",
    "            if i′ == σ[i, j]\n",
    "                P_σ[m, m′] = Q[j, j′]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    # Solve for the value of σ \n",
    "    v_σ = (I - β * P_σ) \\ r_σ\n",
    "    # Return as multi-index array\n",
    "    return reshape(v_σ, yn, zn)\n",
    "end\n",
    "\n",
    "\n",
    "\"Howard policy iteration routine.\"\n",
    "function policy_iteration(model)\n",
    "    yn, zn = length(model.y_grid), length(model.z_grid)\n",
    "    σ = ones(Int32, yn, zn)\n",
    "    i, error = 0, 1.0\n",
    "    while error > 0\n",
    "        v_σ = get_value(σ, model)\n",
    "        σ_new = get_greedy(v_σ, model)\n",
    "        error = maximum(abs.(σ_new - σ))\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        println(\"Concluded loop $i with error $error.\")\n",
    "    end\n",
    "    return σ\n",
    "end\n",
    "\n",
    "\"Optimistic policy iteration routine.\"\n",
    "function optimistic_policy_iteration(model; tol=1e-5, m=100)\n",
    "    v = zeros(length(model.y_grid), length(model.z_grid))\n",
    "    error = tol + 1\n",
    "    while error > tol\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        for i in 1:m\n",
    "            v = T_σ(v, σ, model)\n",
    "        end\n",
    "        error = maximum(abs.(v - last_v))\n",
    "    end\n",
    "    return get_greedy(v, model)\n",
    "end\n",
    "\n",
    "\n",
    "# Plots\n",
    "\n",
    "using PyPlot\n",
    "using LaTeXStrings\n",
    "PyPlot.matplotlib[:rc](\"text\", usetex=true) # allow tex rendering\n",
    "fontsize=12\n",
    "\n",
    "function plot_policy()\n",
    "    model = create_investment_model()\n",
    "    (; β, a_0, a_1, γ, c, y_grid, z_grid, Q) = model\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(y_grid, y_grid, \"k--\", label=L\"45\")\n",
    "    ax.plot(y_grid, y_grid[σ_star[:, 1]], label=L\"\\sigma^*(\\cdot, z_1)\")\n",
    "    ax.plot(y_grid, y_grid[σ_star[:, end]], label=L\"\\sigma^*(\\cdot, z_N)\")\n",
    "    ax.legend(fontsize=fontsize)\n",
    "end\n",
    "\n",
    "function plot_sim(; savefig=false, figname=\"../figures/finite_lq_1.pdf\")\n",
    "    ts_length = 200\n",
    "\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(9, 11.2))\n",
    "\n",
    "    for (ax, γ) in zip(axes, (1, 10, 20, 30))\n",
    "        model = create_investment_model(γ=γ)\n",
    "        (; β, a_0, a_1, γ, c, y_grid, z_grid, Q) = model\n",
    "        σ_star = optimistic_policy_iteration(model)\n",
    "        mc = MarkovChain(Q, z_grid)\n",
    "\n",
    "        z_sim_idx = simulate_indices(mc, ts_length)\n",
    "        z_sim = z_grid[z_sim_idx]\n",
    "        y_sim_idx = Vector{Int32}(undef, ts_length)\n",
    "        y_1 = (a_0 - c + z_sim[1]) / (2 * a_1)\n",
    "        y_sim_idx[1] = searchsortedfirst(y_grid, y_1)\n",
    "        for t in 1:(ts_length-1)\n",
    "            y_sim_idx[t+1] = σ_star[y_sim_idx[t], z_sim_idx[t]]\n",
    "        end\n",
    "        y_sim = y_grid[y_sim_idx]\n",
    "        y_bar_sim = (a_0 .- c .+ z_sim) ./ (2 * a_1)\n",
    "\n",
    "        ax.plot(1:ts_length, y_sim, label=L\"Y_t\")\n",
    "        ax.plot(1:ts_length, y_bar_sim, label=L\"\\bar Y_t\")\n",
    "        ax.legend(fontsize=fontsize, frameon=false, loc=\"upper right\")\n",
    "        ax.set_ylabel(\"output\", fontsize=fontsize)\n",
    "        ax.set_ylim(1, 9)\n",
    "        ax.set_title(L\"\\gamma = \" * \"$γ\", fontsize=fontsize)\n",
    "    end\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function plot_timing(; m_vals=collect(range(1, 600, step=10)),\n",
    "                   savefig=false,\n",
    "                   figname=\"../figures/finite_lq_time.pdf\"\n",
    "    )\n",
    "    model = create_investment_model()\n",
    "    #println(\"Running Howard policy iteration.\")\n",
    "    #pi_time = @elapsed σ_pi = policy_iteration(model)\n",
    "    #println(\"PI completed in $pi_time seconds.\")\n",
    "    println(\"Running value function iteration.\")\n",
    "    vfi_time = @elapsed σ_vfi = value_iteration(model, tol=1e-5)\n",
    "    println(\"VFI completed in $vfi_time seconds.\")\n",
    "    #@assert σ_vfi == σ_pi \"Warning: policies deviated.\"\n",
    "    opi_times = []\n",
    "    for m in m_vals\n",
    "        println(\"Running optimistic policy iteration with m=$m.\")\n",
    "        opi_time = @elapsed σ_opi = \n",
    "            optimistic_policy_iteration(model, m=m, tol=1e-5)\n",
    "        println(\"OPI with m=$m completed in $opi_time seconds.\")\n",
    "        #@assert σ_opi == σ_pi \"Warning: policies deviated.\"\n",
    "        push!(opi_times, opi_time)\n",
    "    end\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    #ax.plot(m_vals, fill(pi_time, length(m_vals)), \n",
    "    #        lw=2, label=\"Howard policy iteration\")\n",
    "    ax.plot(m_vals, fill(vfi_time, length(m_vals)), \n",
    "            lw=2, label=\"value function iteration\")\n",
    "    ax.plot(m_vals, opi_times, lw=2, label=\"optimistic policy iteration\")\n",
    "    ax.legend(fontsize=fontsize, frameon=false)\n",
    "    ax.set_xlabel(L\"m\", fontsize=fontsize)\n",
    "    ax.set_ylabel(\"time\", fontsize=fontsize)\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "    return (vfi_time, opi_times)\n",
    "    #return (pi_time, vfi_time, opi_times)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sim(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timing(savefig=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a08fd",
   "metadata": {},
   "source": [
    "#### firm_hiring.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5fe2b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "using QuantEcon, LinearAlgebra, IterTools\n",
    "\n",
    "function create_hiring_model(; \n",
    "        r=0.04,                              # Interest rate\n",
    "        κ=1.0,                               # Adjustment cost \n",
    "        α=0.4,                               # Production parameter\n",
    "        p=1.0, w=1.0,                        # Price and wage\n",
    "        l_min=0.0, l_max=30.0, l_size=100,   # Grid for labor\n",
    "        ρ=0.9, ν=0.4, b=1.0,                 # AR(1) parameters\n",
    "        z_size=100)                          # Grid size for shock\n",
    "    β = 1/(1+r) \n",
    "    l_grid = LinRange(l_min, l_max, l_size)  \n",
    "    mc = tauchen(z_size, ρ, ν, b, 6)\n",
    "    z_grid, Q = mc.state_values, mc.p\n",
    "    return (; β, κ, α, p, w, l_grid, z_grid, Q)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "The aggregator B is given by \n",
    "\n",
    "    B(l, z, l′) = r(l, z, l′) + β Σ_z′ v(l′, z′) Q(z, z′).\"\n",
    "\n",
    "where \n",
    "\n",
    "    r(l, z, l′) := p * z * f(l) - w * l - κ 1{l != l′}\n",
    "\n",
    "\"\"\"\n",
    "function B(i, j, k, v, model)\n",
    "    (; β, κ, α, p, w, l_grid, z_grid, Q) = model\n",
    "    l, z, l′ = l_grid[i], z_grid[j], l_grid[k]\n",
    "    r = p * z * l^α - w * l - κ * (l != l′)\n",
    "    return @views r + β * dot(v[k, :], Q[j, :]) \n",
    "end\n",
    "\n",
    "\n",
    "\"The policy operator.\"\n",
    "function T_σ(v, σ, model)\n",
    "    l_idx, z_idx = (eachindex(g) for g in (model.l_grid, model.z_grid))\n",
    "    v_new = similar(v)\n",
    "    for (i, j) in product(l_idx, z_idx)\n",
    "        v_new[i, j] = B(i, j, σ[i, j], v, model) \n",
    "    end\n",
    "    return v_new\n",
    "end\n",
    "\n",
    "\"Compute a v-greedy policy.\"\n",
    "function get_greedy(v, model)\n",
    "    (; β, κ, α, p, w, l_grid, z_grid, Q) = model\n",
    "    l_idx, z_idx = (eachindex(g) for g in (model.l_grid, model.z_grid))\n",
    "    σ = Matrix{Int32}(undef, length(l_idx), length(z_idx))\n",
    "    for (i, j) in product(l_idx, z_idx)\n",
    "        _, σ[i, j] = findmax(B(i, j, k, v, model) for k in l_idx)\n",
    "    end\n",
    "    return σ\n",
    "end\n",
    "\n",
    "\"Optimistic policy iteration routine.\"\n",
    "function optimistic_policy_iteration(model; tolerance=1e-5, m=100)\n",
    "    v = zeros(length(model.l_grid), length(model.z_grid))\n",
    "    error = tolerance + 1\n",
    "    while error > tolerance\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        for i in 1:m\n",
    "            v = T_σ(v, σ, model)\n",
    "        end\n",
    "        error = maximum(abs.(v - last_v))\n",
    "    end\n",
    "    return get_greedy(v, model)\n",
    "end\n",
    "\n",
    "\n",
    "# Plots\n",
    "\n",
    "using PyPlot\n",
    "using LaTeXStrings\n",
    "PyPlot.matplotlib[:rc](\"text\", usetex=true) # allow tex rendering\n",
    "fontsize=14\n",
    "\n",
    "function plot_policy(; savefig=false, \n",
    "                    figname=\"../figures/firm_hiring_pol.pdf\")\n",
    "    model = create_hiring_model()\n",
    "    (; β, κ, α, p, w, l_grid, z_grid, Q) = model\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(l_grid, l_grid, \"k--\", label=L\"45\")\n",
    "    ax.plot(l_grid, l_grid[σ_star[:, 1]], label=L\"\\sigma^*(\\cdot, z_1)\")\n",
    "    ax.plot(l_grid, l_grid[σ_star[:, end]], label=L\"\\sigma^*(\\cdot, z_N)\")\n",
    "    ax.legend(fontsize=fontsize)\n",
    "end\n",
    "\n",
    "\n",
    "function sim_dynamics(model, ts_length)\n",
    "\n",
    "    (; β, κ, α, p, w, l_grid, z_grid, Q) = model\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "    mc = MarkovChain(Q, z_grid)\n",
    "    z_sim_idx = simulate_indices(mc, ts_length)\n",
    "    z_sim = z_grid[z_sim_idx]\n",
    "    l_sim_idx = Vector{Int32}(undef, ts_length)\n",
    "    l_sim_idx[1] = 32\n",
    "    for t in 1:(ts_length-1)\n",
    "        l_sim_idx[t+1] = σ_star[l_sim_idx[t], z_sim_idx[t]]\n",
    "    end\n",
    "    l_sim = l_grid[l_sim_idx]\n",
    "\n",
    "    y_sim = similar(l_sim)\n",
    "    for (i, l) in enumerate(l_sim)\n",
    "        y_sim[i] = p * z_sim[i] * l_sim[i]^α\n",
    "    end\n",
    "\n",
    "    t = ts_length - 1\n",
    "    l_g, y_g, z_g = zeros(t), zeros(t), zeros(t)\n",
    "\n",
    "    for i in 1:t\n",
    "        l_g[i] = (l_sim[i+1] - l_sim[i]) / l_sim[i]\n",
    "        y_g[i] = (y_sim[i+1] - y_sim[i]) / y_sim[i]\n",
    "        z_g[i] = (z_sim[i+1] - z_sim[i]) / z_sim[i]\n",
    "    end\n",
    "\n",
    "    return l_sim, y_sim, z_sim, l_g, y_g, z_g\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function plot_sim(; savefig=false, \n",
    "                    figname=\"../figures/firm_hiring_ts.pdf\",\n",
    "                    ts_length = 250)\n",
    "\n",
    "    model = create_hiring_model()\n",
    "    (; β, κ, α, p, w, l_grid, z_grid, Q) = model\n",
    "    l_sim, y_sim, z_sim, l_g, y_g, z_g = sim_dynamics(model, ts_length)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(1:ts_length, l_sim, label=L\"\\ell_t\")\n",
    "    ax.plot(1:ts_length, z_sim, alpha=0.6, label=L\"Z_t\")\n",
    "    ax.legend(fontsize=fontsize, frameon=false)\n",
    "    ax.set_ylabel(\"employment\", fontsize=fontsize)\n",
    "    ax.set_xlabel(\"time\", fontsize=fontsize)\n",
    "\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function plot_growth(; savefig=false, \n",
    "                    figname=\"../figures/firm_hiring_g.pdf\",\n",
    "                    ts_length = 10_000_000)\n",
    "\n",
    "    model = create_hiring_model()\n",
    "    (; β, κ, α, p, w, l_grid, z_grid, Q) = model\n",
    "    l_sim, y_sim, z_sim, l_g, y_g, z_g = sim_dynamics(model, ts_length)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(l_g, alpha=0.6, bins=100)\n",
    "    ax.set_xlabel(\"growth\", fontsize=fontsize)\n",
    "\n",
    "    #fig, axes = plt.subplots(2, 1)\n",
    "    #series = y_g, z_g\n",
    "    #for (ax, g) in zip(axes, series)\n",
    "    #    ax.hist(g, alpha=0.6, bins=100)\n",
    "    #    ax.set_xlabel(\"growth\", fontsize=fontsize)\n",
    "    #end\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14fc0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sim(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_growth(savefig=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9abc5e",
   "metadata": {},
   "source": [
    "#### modified_opt_savings.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7ffbf",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "using QuantEcon, LinearAlgebra, IterTools\n",
    "\n",
    "function create_savings_model(; β=0.98, γ=2.5,  \n",
    "                                w_min=0.01, w_max=20.0, w_size=100,\n",
    "                                ρ=0.9, ν=0.1, y_size=20,\n",
    "                                η_min=0.75, η_max=1.25, η_size=2)\n",
    "    η_grid = LinRange(η_min, η_max, η_size)  \n",
    "    ϕ = ones(η_size) * (1 / η_size)  # Uniform distributoin\n",
    "    w_grid = LinRange(w_min, w_max, w_size)  \n",
    "    mc = tauchen(y_size, ρ, ν)\n",
    "    y_grid, Q = exp.(mc.state_values), mc.p\n",
    "    return (; β, γ, η_grid, ϕ, w_grid, y_grid, Q)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "## == Functions for regular OPI == ##\n",
    "\n",
    "\"\"\"\n",
    "B(w, y, η, w′) = u(w + y - w′/η)) + β Σ v(w′, y′, η′) Q(y, y′) ϕ(η′)\n",
    "\"\"\"\n",
    "function B(i, j, k, l, v, model)\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    w, y, η, w′ = w_grid[i], y_grid[j], η_grid[k], w_grid[l]\n",
    "    u(c) = c^(1-γ)/(1-γ)\n",
    "    c = w + y - (w′/ η)\n",
    "    exp_value = 0.0\n",
    "    for m in eachindex(y_grid)\n",
    "        for n in eachindex(η_grid)\n",
    "            exp_value += v[l, m, n] * Q[j, m] * ϕ[n]\n",
    "        end\n",
    "    end\n",
    "    return c > 0 ? u(c) + β * exp_value : -Inf\n",
    "end\n",
    "\n",
    "\"The policy operator.\"\n",
    "function T_σ(v, σ, model)\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    grids = w_grid, y_grid, η_grid\n",
    "    w_idx, y_idx, η_idx = (eachindex(g) for g in grids)\n",
    "    v_new = similar(v)\n",
    "    for (i, j, k) in product(w_idx, y_idx, η_idx)\n",
    "        v_new[i, j, k] = B(i, j, k, σ[i, j, k], v, model) \n",
    "    end\n",
    "    return v_new\n",
    "end\n",
    "\n",
    "\"Compute a v-greedy policy.\"\n",
    "function get_greedy(v, model)\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    w_idx, y_idx, η_idx = (eachindex(g) for g in (w_grid, y_grid, η_grid))\n",
    "    σ = Array{Int32}(undef, length(w_idx), length(y_idx), length(η_idx))\n",
    "    for (i, j, k) in product(w_idx, y_idx, η_idx)\n",
    "        _, σ[i, j, k] = findmax(B(i, j, k, l, v, model) for l in w_idx)\n",
    "    end\n",
    "    return σ\n",
    "end\n",
    "\n",
    "\n",
    "\"Optimistic policy iteration routine.\"\n",
    "function optimistic_policy_iteration(model; tolerance=1e-5, m=100)\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    v = zeros(length(w_grid), length(y_grid), length(η_grid))\n",
    "    error = tolerance + 1\n",
    "    while error > tolerance\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        for i in 1:m\n",
    "            v = T_σ(v, σ, model)\n",
    "        end\n",
    "        error = maximum(abs.(v - last_v))\n",
    "        println(\"OPI current error = $error\")\n",
    "    end\n",
    "    return get_greedy(v, model)\n",
    "end\n",
    "\n",
    "\n",
    "## == Functions for modified OPI == ##\n",
    "\n",
    "\"D(w, y, η, w′, g) = u(w + y - w′/η) + β g(y, w′).\"\n",
    "@inline function D(i, j, k, l, g, model)\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    w, y, η, w′ = w_grid[i], y_grid[j], η_grid[k], w_grid[l]\n",
    "    u(c) = c^(1-γ)/(1-γ)\n",
    "    c = w + y - (w′/η)\n",
    "    return c > 0 ? u(c) + β * g[j, l] : -Inf\n",
    "end\n",
    "\n",
    "\n",
    "\"Compute a g-greedy policy.\"\n",
    "function get_g_greedy(g, model)\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    w_idx, y_idx, η_idx = (eachindex(g) for g in (w_grid, y_grid, η_grid))\n",
    "    σ = Array{Int32}(undef, length(w_idx), length(y_idx), length(η_idx))\n",
    "    for (i, j, k) in product(w_idx, y_idx, η_idx)\n",
    "        _, σ[i, j, k] = findmax(D(i, j, k, l, g, model) for l in w_idx)\n",
    "    end\n",
    "    return σ\n",
    "end\n",
    "\n",
    "\n",
    "\"The modified policy operator.\"\n",
    "function R_σ(g, σ, model)\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    w_idx, y_idx, η_idx = (eachindex(g) for g in (w_grid, y_grid, η_grid))\n",
    "    g_new = similar(g)\n",
    "    for (j, i′) in product(y_idx, w_idx)  # j indexes y, i′ indexes w′ \n",
    "        out = 0.0\n",
    "        for j′ in y_idx                   # j′ indexes y′\n",
    "            for k′ in η_idx               # k′ indexes η′\n",
    "                out += D(i′, j′, k′, σ[i′, j′, k′], g, model) * \n",
    "                        Q[j, j′] * ϕ[k′]\n",
    "            end\n",
    "        end\n",
    "        g_new[j, i′] = out\n",
    "    end\n",
    "    return g_new\n",
    "end\n",
    "\n",
    "\n",
    "\"Modified optimistic policy iteration routine.\"\n",
    "function mod_opi(model; tolerance=1e-5, m=100)\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    g = zeros(length(y_grid), length(w_grid))\n",
    "    error = tolerance + 1\n",
    "    while error > tolerance\n",
    "        last_g = g\n",
    "        σ = get_g_greedy(g, model)\n",
    "        for i in 1:m\n",
    "            g = R_σ(g, σ, model)\n",
    "        end\n",
    "        error = maximum(abs.(g - last_g))\n",
    "        println(\"OPI current error = $error\")\n",
    "    end\n",
    "    return get_g_greedy(g, model)\n",
    "end\n",
    "\n",
    "\n",
    "# == Simulations and inequality measures == #\n",
    "\n",
    "function simulate_wealth(m)\n",
    "\n",
    "    model = create_savings_model()\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    σ_star = mod_opi(model)\n",
    "\n",
    "    # Simulate labor income\n",
    "    mc = MarkovChain(Q)\n",
    "    y_idx_series = simulate(mc, m)\n",
    "\n",
    "    # IID Markov chain with uniform draws\n",
    "    l = length(η_grid)\n",
    "    mc = MarkovChain(ones(l, l) * (1/l))\n",
    "    η_idx_series = simulate(mc, m)\n",
    "\n",
    "    w_idx_series = similar(y_idx_series)\n",
    "    w_idx_series[1] = 1\n",
    "    for t in 1:(m-1)\n",
    "        i, j, k = w_idx_series[t], y_idx_series[t], η_idx_series[t]\n",
    "        w_idx_series[t+1] = σ_star[i, j, k]\n",
    "    end\n",
    "\n",
    "    w_series = w_grid[w_idx_series]\n",
    "    return w_series\n",
    "end\n",
    "\n",
    "\n",
    "function lorenz(v)  # assumed sorted vector\n",
    "    S = cumsum(v)  # cumulative sums: [v[1], v[1] + v[2], ... ]\n",
    "    F = (1:length(v)) / length(v)\n",
    "    L = S ./ S[end]\n",
    "    return (; F, L) # returns named tuple\n",
    "end\n",
    "\n",
    "\n",
    "gini(v) = (2 * sum(i * y for (i,y) in enumerate(v))/sum(v)\n",
    "           - (length(v) + 1))/length(v)\n",
    "\n",
    "\n",
    "# == Plots == #\n",
    "\n",
    "using PyPlot\n",
    "using LaTeXStrings\n",
    "PyPlot.matplotlib[:rc](\"text\", usetex=true) # allow tex rendering\n",
    "fontsize=16\n",
    "\n",
    "\n",
    "\n",
    "function plot_contours(; savefig=false, \n",
    "                         figname=\"../figures/modified_opt_savings_1.pdf\")\n",
    "\n",
    "    model = create_savings_model()\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "    y_idx, η_idx = eachindex(y_grid), eachindex(η_grid)\n",
    "    H = zeros(length(y_grid), length(η_grid))\n",
    "\n",
    "    w_indices = (1, length(w_grid))\n",
    "    titles = \"low wealth\", \"high wealth\"\n",
    "    for (ax, w_idx, title) in zip(axes, w_indices, titles)\n",
    "\n",
    "        for (i_y, i_ϵ) in product(y_idx, η_idx)\n",
    "            w, y, η = w_grid[w_idx], y_grid[i_y], η_grid[i_ϵ]\n",
    "            H[i_y, i_ϵ] = w_grid[σ_star[w_idx, i_y, i_ϵ]] / (w+y)\n",
    "        end\n",
    "\n",
    "        cs1 = ax.contourf(y_grid, η_grid, transpose(H), alpha=0.5)\n",
    "        plt.colorbar(cs1, ax=ax) #, format=\"%.6f\")\n",
    "\n",
    "        ax.set_title(title, fontsize=fontsize)\n",
    "        ax.set_xlabel(L\"y\", fontsize=fontsize)\n",
    "        ax.set_ylabel(L\"\\varepsilon\", fontsize=fontsize)\n",
    "    end\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function plot_policies(; savefig=false, \n",
    "                         figname=\"../figures/modified_opt_savings_2.pdf\")\n",
    "\n",
    "    model = create_savings_model()\n",
    "    (; β, γ, η_grid, ϕ, w_grid, y_grid, Q) = model\n",
    "    σ_star = mod_opi(model)\n",
    "    y_bar = floor(Int, length(y_grid) / 2)  # Index of mid-point of y_grid\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_grid, w_grid, \"k--\", label=L\"45\")\n",
    "\n",
    "    for (i, η) in enumerate(η_grid)\n",
    "        label = L\"\\sigma^*\" * \" at \" * L\"\\eta = \" * \"$η\"\n",
    "        ax.plot(w_grid, w_grid[σ_star[:, y_bar, i]], label=label)\n",
    "    end\n",
    "    ax.legend(fontsize=fontsize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function plot_time_series(; m=2_000,\n",
    "                           savefig=false, \n",
    "                           figname=\"../figures/modified_opt_savings_ts.pdf\")\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_series, label=L\"w_t\")\n",
    "    ax.legend(fontsize=fontsize)\n",
    "    ax.set_xlabel(\"time\", fontsize=fontsize)\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "function plot_histogram(; m=1_000_000,\n",
    "                           savefig=false, \n",
    "                           figname=\"../figures/modified_opt_savings_hist.pdf\")\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    g = round(gini(sort(w_series)), digits=2)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.hist(w_series, bins=40, density=true)\n",
    "    ax.set_xlabel(\"wealth\", fontsize=fontsize)\n",
    "    ax.text(15, 0.7, \"Gini = $g\", fontsize=fontsize)\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function plot_lorenz(; m=1_000_000,\n",
    "                           savefig=false, \n",
    "                           figname=\"../figures/modified_opt_savings_lorenz.pdf\")\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    (; F, L) = lorenz(sort(w_series))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(F, F, label=\"Lorenz curve, equality\")\n",
    "    ax.plot(F, L, label=\"Lorenz curve, wealth distribution\")\n",
    "    ax.legend()\n",
    "    if savefig\n",
    "        fig.savefig(figname)\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb71c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contours(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_policies(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28185cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79c6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05195132",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(savefig=true)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Julia",
   "language": "julia",
   "name": "julia-1.9"
  },
  "source_map": [
   10,
   28,
   35,
   38,
   157,
   161,
   163,
   165,
   211,
   213,
   259,
   261,
   447,
   451,
   455,
   459,
   463,
   465,
   467,
   697,
   701,
   705,
   707,
   709,
   886,
   890,
   894,
   896,
   898,
   1198,
   1202,
   1206,
   1210,
   1214
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}