{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4819cda",
   "metadata": {},
   "source": [
    "(Chapter 3: Markov Dynamics)=\n",
    "```{raw} html\n",
    "<div id=\"qe-notebook-header\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>\n",
    "```\n",
    "# Chapter 3: Markov Dynamics\n",
    "\n",
    "\n",
    "```{contents} Contents\n",
    ":depth: 2\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### inventory_sim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6db73",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import geom\n",
    "from itertools import product\n",
    "from quantecon import MarkovChain\n",
    "from collections import namedtuple\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"S\", \"s\", \"p\", \"φ\", \"h\"))\n",
    "\n",
    "def create_inventory_model(S=100,   # Order size\n",
    "                           s=10,    # Order threshold\n",
    "                           p=0.4):  # Demand parameter\n",
    "    φ = geom(p, loc=-1) # loc sets support to {0,1,...}\n",
    "    h = lambda x, d: max(x - d, 0) + S*(x <= s)\n",
    "    return Model(S=S, s=s, p=p, φ=φ, h=h)\n",
    "\n",
    "\n",
    "def sim_inventories(model, ts_length=200):\n",
    "    \"\"\"Simulate the inventory process.\"\"\"\n",
    "    S, s, p, φ, h = model\n",
    "    X = np.empty(ts_length)\n",
    "    X[0] = S  # Initial condition\n",
    "    for t in range(0, ts_length - 1):\n",
    "        X[t+1] = h(X[t], φ.rvs())\n",
    "    return X\n",
    "\n",
    "\n",
    "def compute_mc(model, d_max=100):\n",
    "    \"\"\"Compute the transition probabilities and state.\"\"\"\n",
    "    S, s, p, φ, h = model\n",
    "    n = S + s + 1  # Size of state space\n",
    "    state_vals = np.arange(n)\n",
    "    P = np.empty((n, n))\n",
    "    for (i, j) in product(range(0, n), range(0, n)):\n",
    "        P[i, j] = sum((h(i, d) == j)*φ.pmf(d) for d in range(d_max+1))\n",
    "    return MarkovChain(P, state_vals)\n",
    "\n",
    "\n",
    "def compute_stationary_dist(model):\n",
    "    \"\"\"Compute the stationary distribution of the model.\"\"\"\n",
    "    mc = compute_mc(model)\n",
    "    return mc.state_values, mc.stationary_distributions[0]\n",
    "\n",
    "\n",
    "\n",
    "# Plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"text.usetex\": True, \"font.size\": 14})\n",
    "\n",
    "\n",
    "default_model = create_inventory_model()\n",
    "\n",
    "\n",
    "def plot_ts(model, fontsize=16,\n",
    "                   figname=\"../figures/inventory_sim_1.pdf\",\n",
    "                   savefig=False):\n",
    "    S, s, p, φ, h = model\n",
    "    X = sim_inventories(model)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(X, label=r\"$X_t$\", linewidth=3, alpha=0.6)\n",
    "    fontdict = {'fontsize': fontsize}\n",
    "    ax.set_xlabel(r\"$t$\", fontdict=fontdict)\n",
    "    ax.set_ylabel(\"inventory\", fontdict=fontdict)\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "    ax.set_ylim(0, S + s + 20)\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "\n",
    "def plot_hist(model, fontsize=16,\n",
    "                   figname=\"../figures/inventory_sim_2.pdf\",\n",
    "                   savefig=False):\n",
    "    S, s, p, φ, h = model\n",
    "    state_values, ψ_star = compute_stationary_dist(model)\n",
    "    X = sim_inventories(model, 1_000_000)\n",
    "    histogram = [np.mean(X == i) for i in state_values]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(state_values, ψ_star, \"k-\",  linewidth=3, alpha=0.7,\n",
    "                label=r\"$\\psi^*$\")\n",
    "    ax.bar(state_values, histogram, alpha=0.7, label=\"frequency\")\n",
    "    fontdict = {'fontsize': fontsize}\n",
    "    ax.set_xlabel(\"state\", fontdict=fontdict)\n",
    "\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "    ax.set_ylim(0, 0.015)\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74289159",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_inventory_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ts(model, savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(model, savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9e0c5",
   "metadata": {},
   "source": [
    "#### is_irreducible.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f14792",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from quantecon import MarkovChain\n",
    "import numpy as np\n",
    "\n",
    "P = np.array([\n",
    "    [0.1, 0.9],\n",
    "    [0.0, 1.0]\n",
    "])\n",
    "\n",
    "mc = MarkovChain(P)\n",
    "print(mc.is_irreducible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d0517",
   "metadata": {},
   "source": [
    "#### laborer_sim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660d67b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"α\", \"β\"))\n",
    "\n",
    "\n",
    "def create_laborer_model(α=0.3, β=0.2):\n",
    "    return Model(α=α, β=β)\n",
    "\n",
    "\n",
    "def laborer_update(x, model):  # update X from t to t+1\n",
    "    if x == 1:\n",
    "        x_ = 2 if np.random.rand() < model.α else 1\n",
    "    else:\n",
    "        x_ = 1 if np.random.rand() < model.β else 2\n",
    "    return x_\n",
    "\n",
    "\n",
    "def sim_chain(k, p, model):\n",
    "    X = np.empty(k)\n",
    "    X[0] = 1 if np.random.rand() < p else 2\n",
    "    for t in range(0, k-1):\n",
    "        X[t+1] = laborer_update(X[t], model)\n",
    "    return X\n",
    "\n",
    "\n",
    "def test_convergence(k=10_000_000, p=0.5):\n",
    "    model = create_laborer_model()\n",
    "    α, β = model\n",
    "    ψ_star = (1/(α + β)) * np.array([β, α])\n",
    "    X = sim_chain(k, p, model)\n",
    "    ψ_e = (1/k) * np.array([sum(X == 1), sum(X == 2)])\n",
    "    error = np.max(np.abs(ψ_star - ψ_e))\n",
    "    approx_equal = np.allclose(ψ_star, ψ_e, rtol=0.01)\n",
    "    print(f\"Sup norm deviation is {error}\")\n",
    "    print(f\"Approximate equality is {approx_equal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf75b28",
   "metadata": {},
   "source": [
    "#### markov_js.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5183c08",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Infinite-horizon job search with Markov wage draws.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from quantecon.markov import tauchen\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from s_approx import successive_approx\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"n\", \"w_vals\", \"P\", \"β\", \"c\"))\n",
    "\n",
    "def create_markov_js_model(\n",
    "        n=200,       # wage grid size\n",
    "        ρ=0.9,       # wage persistence\n",
    "        ν=0.2,       # wage volatility\n",
    "        β=0.98,      # discount factor\n",
    "        c=1.0        # unemployment compensation\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Creates an instance of the job search model with Markov wages.\n",
    "    \"\"\"\n",
    "    mc = tauchen(n, ρ, ν)\n",
    "    w_vals, P = np.exp(mc.state_values), mc.P\n",
    "    return Model(n=n, w_vals=w_vals, P=P, β=β, c=c)\n",
    "\n",
    "\n",
    "def T(v, model):\n",
    "    \"\"\"\n",
    "    The Bellman operator Tv = max{e, c + β P v} with e(w) = w / (1-β).\n",
    "    \"\"\"\n",
    "    n, w_vals, P, β, c = model\n",
    "    h = c + β * np.dot(P, v)\n",
    "    e = w_vals / (1 - β)\n",
    "    return np.maximum(e, h)\n",
    "\n",
    "\n",
    "def get_greedy(v, model):\n",
    "    \"\"\"Get a v-greedy policy.\"\"\"\n",
    "    n, w_vals, P, β, c = model\n",
    "    σ = w_vals / (1 - β) >= c + β * np.dot(P, v)\n",
    "    return σ\n",
    "\n",
    "\n",
    "\n",
    "def vfi(model):\n",
    "    \"\"\"Solve the infinite-horizon Markov job search model by VFI.\"\"\"\n",
    "    v_init = np.zeros(model.w_vals.shape)\n",
    "    v_star = successive_approx(lambda v: T(v, model), v_init)\n",
    "    σ_star = get_greedy(v_star, model)\n",
    "    return v_star, σ_star\n",
    "\n",
    "\n",
    "\n",
    "# == Policy iteration == #\n",
    "\n",
    "\n",
    "def get_value(σ, model):\n",
    "    \"\"\"Get the value of policy σ.\"\"\"\n",
    "    n, w_vals, P, β, c = model\n",
    "    e = w_vals / (1 - β)\n",
    "    K_σ = β * ((1 - σ) * P.T).T\n",
    "    r_σ = σ * e + (1 - σ) * c\n",
    "    I = np.identity(K_σ.shape[0])\n",
    "    return np.linalg.solve((I - K_σ), r_σ)\n",
    "\n",
    "\n",
    "def policy_iteration(model):\n",
    "    \"\"\"\n",
    "    Howard policy iteration routine.\n",
    "    \"\"\"\n",
    "    σ = np.zeros(model.n, dtype=bool)\n",
    "    i, error = 0, True\n",
    "    while error:\n",
    "        v_σ = get_value(σ, model)\n",
    "        σ_new = get_greedy(v_σ, model)\n",
    "        error = np.any(σ_new ^ σ)\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        print(f\"Concluded loop {i} with error: {error}.\")\n",
    "    return σ\n",
    "\n",
    "\n",
    "# == Plots == #\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"text.usetex\": True, \"font.size\": 14})\n",
    "\n",
    "\n",
    "default_model = create_markov_js_model()\n",
    "\n",
    "\n",
    "def plot_main(model=default_model,\n",
    "               method=\"vfi\",\n",
    "               savefig=False,\n",
    "               figname=\"../figures/markov_js_vfix.png\"):\n",
    "    n, w_vals, P, β, c = model\n",
    "\n",
    "    if method == \"vfi\":\n",
    "        v_star, σ_star = vfi(model)\n",
    "    else:\n",
    "        σ_star = policy_iteration(model)\n",
    "        v_star = get_value(σ_star, model)\n",
    "\n",
    "    h_star = c + β * np.dot(P, v_star)\n",
    "    e = w_vals / (1 - β)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_vals, h_star, linewidth=4, ls=\"--\", alpha=0.4, label=r\"$h^*(w)$\")\n",
    "    ax.plot(w_vals, e, linewidth=4, ls=\"--\", alpha=0.4, label=r\"$w/(1-\\beta)$\")\n",
    "    ax.plot(w_vals, np.maximum(e, h_star), \"k-\", alpha=0.7, label=r\"$v^*(w)$\")\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(r\"$w$\")\n",
    "    if savefig:\n",
    "        fig.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e36099",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_main(savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03328449",
   "metadata": {},
   "source": [
    "#### markov_js_with_sep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda80ca",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Infinite-horizon job search with Markov wage draws and separation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from quantecon.markov import tauchen\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from s_approx import successive_approx\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"n\", \"w_vals\", \"P\", \"β\", \"c\", \"α\"))\n",
    "\n",
    "\n",
    "def create_js_with_sep_model(\n",
    "        n=200,          # wage grid size\n",
    "        ρ=0.9, ν=0.2,   # wage persistence and volatility\n",
    "        β=0.98, α=0.1,  # discount factor and separation rate\n",
    "        c=1.0):         # unemployment compensation\n",
    "    \"\"\"Creates an instance of the job search model with separation.\"\"\"\n",
    "    mc = tauchen(n, ρ, ν)\n",
    "    w_vals, P = np.exp(mc.state_values), mc.P\n",
    "    return Model(n=n, w_vals=w_vals, P=P, β=β, c=c, α=α)\n",
    "\n",
    "\n",
    "def T(v, model):\n",
    "    \"\"\"The Bellman operator for the value of being unemployed.\"\"\"\n",
    "    n, w_vals, P, β, c, α = model\n",
    "    d = 1 / (1 - β * (1 - α))\n",
    "    accept = d * (w_vals + α * β * np.dot(P, v))\n",
    "    reject = c + β * np.dot(P, v)\n",
    "    return np.maximum(accept, reject)\n",
    "\n",
    "\n",
    "def get_greedy(v, model):\n",
    "    \"\"\" Get a v-greedy policy.\"\"\"\n",
    "    n, w_vals, P, β, c, α = model\n",
    "    d = 1 / (1 - β * (1 - α))\n",
    "    accept = d * (w_vals + α * β * np.dot(P, v))\n",
    "    reject = c + β * np.dot(P, v)\n",
    "    σ = accept >= reject\n",
    "    return σ\n",
    "\n",
    "\n",
    "def vfi(model):\n",
    "    \"\"\"Solve by VFI.\"\"\"\n",
    "    v_init = np.zeros(model.w_vals.shape)\n",
    "    v_star = successive_approx(lambda v: T(v, model), v_init)\n",
    "    σ_star = get_greedy(v_star, model)\n",
    "    return v_star, σ_star\n",
    "\n",
    "\n",
    "\n",
    "# == Plots == #\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"text.usetex\": True, \"font.size\": 14})\n",
    "\n",
    "\n",
    "default_model = create_js_with_sep_model()\n",
    "\n",
    "\n",
    "def plot_main(model=default_model,\n",
    "              savefig=False,\n",
    "              figname=\"../figures/markov_js_with_sep_1.pdf\"):\n",
    "    n, w_vals, P, β, c, α = model\n",
    "    v_star, σ_star = vfi(model)\n",
    "\n",
    "    d = 1 / (1 - β * (1 - α))\n",
    "    accept = d * (w_vals + α * β * np.dot(P, v_star))\n",
    "    h_star = c + β * np.dot(P, v_star)\n",
    "\n",
    "    w_star = np.inf\n",
    "    for (i, w) in enumerate(w_vals):\n",
    "        if accept[i] >= h_star[i]:\n",
    "            w_star = w\n",
    "            break\n",
    "\n",
    "    assert w_star != np.inf, \"Agent never accepts\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_vals, h_star, linewidth=4, ls=\"--\", alpha=0.4,\n",
    "            label=\"continuation value\")\n",
    "    ax.plot(w_vals, accept, linewidth=4, ls=\"--\", alpha=0.4,\n",
    "            label=\"stopping value\")\n",
    "    ax.plot(w_vals, v_star, \"k-\", alpha=0.7, label=r\"$v_u^*(w)$\")\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(r\"$w$\")\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "\n",
    "def plot_w_stars(α_vals=np.linspace(0.0, 1.0, 10),\n",
    "                 savefig=False,\n",
    "                 figname=\"../figures/markov_js_with_sep_2.pdf\"):\n",
    "\n",
    "    w_star_vec = np.empty_like(α_vals)\n",
    "    for (i_α, α) in enumerate(α_vals):\n",
    "        print(i_α, α)\n",
    "        model = create_js_with_sep_model(α=α)\n",
    "        n, w_vals, P, β, c, α = model\n",
    "        v_star, σ_star = vfi(model)\n",
    "\n",
    "        d = 1 / (1 - β * (1 - α))\n",
    "        accept = d * (w_vals + α * β * np.dot(P, v_star))\n",
    "        h_star = c + β * np.dot(P, v_star)\n",
    "\n",
    "        w_star = np.inf\n",
    "        for (i_w, w) in enumerate(w_vals):\n",
    "            if accept[i_w] >= h_star[i_w]:\n",
    "                w_star = w\n",
    "                break\n",
    "\n",
    "        assert w_star != np.inf, \"Agent never accepts\"\n",
    "        w_star_vec[i_α] = w_star\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(α_vals, w_star_vec, linewidth=2, alpha=0.6,\n",
    "            label=\"reservation wage\")\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(r\"$\\alpha$\")\n",
    "    ax.set_xlabel(r\"$w$\")\n",
    "    if savefig:\n",
    "        fig.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca537ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_main(savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a38ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_w_stars(savefig=True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   10,
   30,
   128,
   132,
   136,
   138,
   140,
   153,
   155,
   196,
   198,
   322,
   324,
   326,
   458,
   462
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}