{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50e45b4",
   "metadata": {},
   "source": [
    "(Chapter 6: Stochastic Discounting)=\n",
    "```{raw} html\n",
    "<div id=\"qe-notebook-header\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>\n",
    "```\n",
    "# Chapter 6: Stochastic Discounting\n",
    "\n",
    "\n",
    "```{contents} Contents\n",
    ":depth: 2\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### plot_interest_rates.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ba13f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Nominal interest rate from https://fred.stlouisfed.org/series/GS1\n",
    "# Real interest rate from https://fred.stlouisfed.org/series/WFII10\n",
    "#\n",
    "# Download as CSV files\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_nominal = pd.read_csv(\"./data/GS1.csv\")\n",
    "df_real = pd.read_csv(\"./data/WFII10.csv\")\n",
    "\n",
    "def plot_rates(df, fontsize=16, savefig=True):\n",
    "    r_type = 'nominal' if df.equals(df_nominal) else 'real'\n",
    "    fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    ax.plot(df.iloc[:, 0], df.iloc[:, 1], label=f'{r_type} interest rate')\n",
    "    ax.plot(df.iloc[:, 0], np.zeros(df.iloc[:, 1].size), c='k', ls='--')\n",
    "    ax.set_xlim(df.iloc[0, 0], df.iloc[-1, 0])\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "    if savefig:\n",
    "        fig.savefig(f'../figures/plot_interest_rates_{r_type}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93525c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rates(df_nominal, savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b4b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rates(df_real, savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b5fe5",
   "metadata": {},
   "source": [
    "#### pd_ratio.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9895d2",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Price-dividend ratio in a model with dividend and consumption growth.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from quantecon.markov import tauchen\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"x_vals\", \"P\", \"β\", \"γ\",\n",
    "                            \"μ_c\", \"σ_c\", \"μ_d\", \"σ_d\"))\n",
    "\n",
    "\n",
    "def create_asset_pricing_model(\n",
    "        n=200,               # state grid size\n",
    "        ρ=0.9, ν=0.2,        # state persistence and volatility\n",
    "        β=0.99, γ=2.5,       # discount and preference parameter\n",
    "        μ_c=0.01, σ_c=0.02,  # consumption growth mean and volatility\n",
    "        μ_d=0.02, σ_d=0.1):  # dividend growth mean and volatility\n",
    "    \"\"\"\n",
    "    Creates an instance of the asset pricing model with Markov state.\n",
    "    \"\"\"\n",
    "    mc = tauchen(n, ρ, ν)\n",
    "    x_vals, P = np.exp(mc.state_values), mc.P\n",
    "    return Model(x_vals=x_vals, P=P, β=β, γ=γ,\n",
    "                 μ_c=μ_c, σ_c=σ_c, μ_d=μ_d, σ_d=σ_d)\n",
    "\n",
    "\n",
    "def build_discount_matrix(model):\n",
    "    \"\"\"Build the discount matrix A.\"\"\"\n",
    "    x_vals, P, β, γ, μ_c, σ_c, μ_d, σ_d = model\n",
    "    e = np.exp(μ_d - γ*μ_c + (γ**2 * σ_c**2 + σ_d**2)/2 + (1-γ)*x_vals)\n",
    "    return β * (e * P.T).T\n",
    "\n",
    "\n",
    "\n",
    "def pd_ratio(model):\n",
    "    \"\"\"\n",
    "    Compute the price-dividend ratio associated with the model.\n",
    "    \"\"\"\n",
    "    x_vals, P, β, γ, μ_c, σ_c, μ_d, σ_d = model\n",
    "    A = build_discount_matrix(model)\n",
    "    assert np.max(np.abs(np.linalg.eigvals(A))) < 1, \"Requires r(A) < 1.\"\n",
    "    n = len(x_vals)\n",
    "    I = np.identity(n)\n",
    "    return np.linalg.solve((I - A), np.dot(A, np.ones(n)))\n",
    "\n",
    "\n",
    "# == Plots == #\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "default_model = create_asset_pricing_model()\n",
    "\n",
    "\n",
    "def plot_main(μ_d_vals=(0.02, 0.08),\n",
    "              savefig=False,\n",
    "              figname=\"../figures/pd_ratio_1.pdf\"):\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "\n",
    "    for μ_d in μ_d_vals:\n",
    "        model = create_asset_pricing_model(μ_d=μ_d)\n",
    "        x_vals, P, β, γ, μ_c, σ_c, μ_d, σ_d = model\n",
    "        v_star = pd_ratio(model)\n",
    "        ax.plot(x_vals, v_star, linewidth=2, alpha=0.6,\n",
    "                label=r\"$\\mu_d$=\" + f\"{μ_d}\")\n",
    "\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(r\"$x$\")\n",
    "    if savefig:\n",
    "        fig.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d767994",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_main(savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f41274",
   "metadata": {},
   "source": [
    "#### inventory_sdd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58fb639",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Inventory management model with state-dependent discounting. The discount\n",
    "factor takes the form β_t = Z_t, where (Z_t) is a discretization of a\n",
    "Gaussian AR(1) process\n",
    "\n",
    "    X_t = ρ X_{t-1} + b + ν W_t.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from quantecon import compute_fixed_point\n",
    "from quantecon.markov import tauchen, MarkovChain\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "from numba import njit, prange\n",
    "from collections import namedtuple\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"K\", \"c\", \"κ\", \"p\", \"r\", \n",
    "                             \"R\", \"y_vals\", \"z_vals\", \"Q\"))\n",
    "\n",
    "\n",
    "@njit\n",
    "def ϕ(p, d):\n",
    "    return (1 - p)**d * p\n",
    "\n",
    "@njit\n",
    "def f(y, a, d):\n",
    "    return np.maximum(y - d, 0) + a  # Inventory update\n",
    "\n",
    "def create_sdd_inventory_model(\n",
    "            ρ=0.98, ν=0.002, n_z=20, b=0.97,  # Z state parameters\n",
    "            K=40, c=0.2, κ=0.8, p=0.6,        # firm and demand parameters\n",
    "            d_max=100):                        # truncation of demand shock\n",
    "    d_vals = np.arange(d_max+1)\n",
    "    ϕ_vals = ϕ(p, d_vals)\n",
    "    y_vals = np.arange(K+1)\n",
    "    n_y = len(y_vals)\n",
    "    mc = tauchen(n_z, ρ, ν)\n",
    "    z_vals, Q = mc.state_values + b, mc.P\n",
    "    ρL = np.max(np.abs(np.linalg.eigvals(z_vals * Q)))\n",
    "    assert ρL < 1, \"Error: ρ(L) >= 1.\"    # check r(L) < 1\n",
    "\n",
    "    R = np.zeros((n_y, n_y, n_y))\n",
    "    for i_y, y in enumerate(y_vals):\n",
    "        for i_y_1, y_1 in enumerate(y_vals):\n",
    "            for i_a, a in enumerate(range(K - y + 1)):\n",
    "                hits = [f(y, a, d) == y_1 for d in d_vals]\n",
    "                R[i_y, i_a, i_y_1] = np.dot(hits, ϕ_vals)\n",
    "\n",
    "\n",
    "    r = np.empty((n_y, n_y))\n",
    "    for i_y, y in enumerate(y_vals):\n",
    "        for i_a, a in enumerate(range(K - y + 1)):\n",
    "            cost = c * a + κ * (a > 0)\n",
    "            r[i_y, i_a] = np.dot(np.minimum(y, d_vals),  ϕ_vals) - cost\n",
    "\n",
    "\n",
    "    return Model(K=K, c=c, κ=κ, p=p, r=r, R=R, \n",
    "                 y_vals=y_vals, z_vals=z_vals, Q=Q)\n",
    "\n",
    "@njit\n",
    "def B(i_y, i_z, i_a, v, model):\n",
    "    \"\"\"\n",
    "    The function B(x, z, a, v) = r(x, a) + β(z) Σ_x′ v(x′) P(x, a, x′).\n",
    "    \"\"\"\n",
    "    K, c, κ, p, r, R, y_vals, z_vals, Q = model\n",
    "    β = z_vals[i_z]\n",
    "    cv = 0.0\n",
    "\n",
    "    for i_z_1 in prange(len(z_vals)):\n",
    "        for i_y_1 in prange(len(y_vals)):\n",
    "            cv += v[i_y_1, i_z_1] * R[i_y, i_a, i_y_1] * Q[i_z, i_z_1]\n",
    "    return r[i_y, i_a] + β * cv\n",
    "\n",
    "@njit(parallel=True)\n",
    "def T(v, model):\n",
    "    \"\"\"The Bellman operator.\"\"\"\n",
    "    K, c, κ, p, r, R, y_vals, z_vals, Q = model\n",
    "    new_v = np.empty_like(v)\n",
    "    for i_z in prange(len(z_vals)):\n",
    "        for (i_y, y) in enumerate(y_vals):\n",
    "            Γy = np.arange(K - y + 1)\n",
    "            new_v[i_y, i_z] = np.max(np.array([B(i_y, i_z, i_a, v, model) \n",
    "                               for i_a in Γy]))\n",
    "    return new_v\n",
    "\n",
    "@njit\n",
    "def T_σ(v, σ, model):\n",
    "    \"\"\"The policy operator.\"\"\"\n",
    "    K, c, κ, p, r, R, y_vals, z_vals, Q = model\n",
    "    new_v = np.empty_like(v)\n",
    "    for (i_z, z) in enumerate(z_vals):\n",
    "        for (i_y, y) in enumerate(y_vals):\n",
    "            new_v[i_y, i_z] = B(i_y, i_z, σ[i_y, i_z], v, model)\n",
    "    return new_v\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_greedy(v, model):\n",
    "    \"\"\"Get a v-greedy policy.  Returns a zero-based array.\"\"\"\n",
    "    K, c, κ, p, r, R, y_vals, z_vals, Q = model\n",
    "    n_z = len(z_vals)\n",
    "    σ_star = np.zeros((K+1, n_z), dtype=np.int32)\n",
    "    for (i_z, z) in enumerate(z_vals):\n",
    "        for (i_y, y) in enumerate(y_vals):\n",
    "            Γy = np.arange(K - y + 1)\n",
    "            i_a = np.argmax(np.array([B(i_y, i_z, i_a, v, model) \n",
    "                               for i_a in Γy]))\n",
    "            σ_star[i_y, i_z] = Γy[i_a]\n",
    "    return σ_star\n",
    "\n",
    "@njit\n",
    "def get_value(v_init, σ, m, model):\n",
    "    \"\"\"Approximate lifetime value of policy σ.\"\"\"\n",
    "    v = v_init\n",
    "    for _ in range(m):\n",
    "        v = T_σ(v, σ, model)\n",
    "    return v\n",
    "\n",
    "def solve_inventory_model(v_init, model):\n",
    "    \"\"\"Use successive_approx to get v_star and then compute greedy.\"\"\"\n",
    "    v_star = compute_fixed_point(lambda v: T(v, model), v_init,\n",
    "                                 error_tol=1e-5, max_iter=1000, print_skip=25)\n",
    "    σ_star = get_greedy(v_star, model)\n",
    "    return v_star, σ_star\n",
    "\n",
    "def optimistic_policy_iteration(v_init, \n",
    "                                model,\n",
    "                                tolerance=1e-6, \n",
    "                                max_iter=1_000,\n",
    "                                print_step=10,\n",
    "                                m=60):\n",
    "    v = v_init\n",
    "    error = tolerance + 1\n",
    "    k = 1\n",
    "    while (error > tolerance) and (k < max_iter):\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        v = get_value(v, σ, m, model)\n",
    "        error = np.max(np.abs(v - last_v))\n",
    "        if k % print_step == 0:\n",
    "            print(f\"Completed iteration {k} with error {error}.\")\n",
    "        k += 1\n",
    "    return v, get_greedy(v, model)\n",
    "\n",
    "\n",
    "# == Plots == #\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an instance of the model and solve it\n",
    "model = create_sdd_inventory_model()\n",
    "K, c, κ, p, r, R, y_vals, z_vals, Q = model\n",
    "n_z = len(z_vals)\n",
    "v_init = np.zeros((K+1, n_z), dtype=float)\n",
    "print(\"Solving model.\")\n",
    "v_star, σ_star = optimistic_policy_iteration(v_init, model)\n",
    "z_mc = MarkovChain(Q, z_vals)\n",
    "\n",
    "def sim_inventories(ts_length, X_init=0):\n",
    "    \"\"\"Simulate given the optimal policy.\"\"\"\n",
    "    global p, z_mc\n",
    "    i_z = z_mc.simulate_indices(ts_length, init=1)\n",
    "    X = np.zeros(ts_length, dtype=np.int32)\n",
    "    X[0] = X_init\n",
    "    rand = np.random.default_rng().geometric(p=p, size=ts_length-1) - 1\n",
    "    for t in range(ts_length-1):\n",
    "        X[t+1] = f(X[t], σ_star[X[t], i_z[t]], rand[t])\n",
    "    return X, z_vals[i_z]\n",
    "\n",
    "def plot_ts(ts_length=400,\n",
    "            fontsize=10,\n",
    "            figname=\"../figures/inventory_sdd_ts.pdf\",\n",
    "            savefig=False):\n",
    "    \n",
    "    X, Z = sim_inventories(ts_length)\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(9, 5.5))\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.plot(X, label=\"inventory\", alpha=0.7)\n",
    "    ax.set_xlabel(r\"$t$\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "    ax.set_ylim(0, np.max(X)+3)\n",
    "\n",
    "    # calculate interest rate from discount factors\n",
    "    r = (1 / Z) - 1\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.plot(r, label=r\"$r_t$\", alpha=0.7)\n",
    "    ax.set_xlabel(r\"$t$\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "def plot_timing(m_vals=np.arange(1, 400, 10),\n",
    "                fontsize=16,\n",
    "                savefig=False):\n",
    "    print(\"Running value function iteration.\")\n",
    "    t_start = time()\n",
    "    solve_inventory_model(v_init, model)\n",
    "    vfi_time = time() - t_start\n",
    "    print(f\"VFI completed in {vfi_time} seconds.\")\n",
    "    opi_times = []\n",
    "    for m in m_vals:\n",
    "        print(f\"Running optimistic policy iteration with m = {m}.\")\n",
    "        t_start = time()\n",
    "        optimistic_policy_iteration(v_init, model, m=m)\n",
    "        opi_time = time() - t_start\n",
    "        print(f\"OPI with m = {m} completed in {opi_time} seconds.\")\n",
    "        opi_times.append(opi_time)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(m_vals, np.full(len(m_vals), vfi_time),\n",
    "            lw=2, label=\"value function iteration\")\n",
    "    ax.plot(m_vals, opi_times, lw=2, label=\"optimistic policy iteration\")\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "    ax.set_xlabel(r\"$m$\", fontsize=fontsize)\n",
    "    ax.set_ylabel(\"time\", fontsize=fontsize)\n",
    "    if savefig:\n",
    "        fig.savefig(\"../figures/inventory_sdd_timing.pdf\")\n",
    "    return (opi_time, vfi_time, opi_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ts(savefig=True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   10,
   30,
   56,
   60,
   62,
   64,
   144,
   146,
   148,
   375
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}